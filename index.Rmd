--- 
title: "Untitled" 
author: "Anonymous" 
output: html_document 
---


```{r setup} 
library(tidyverse)

function_files <- list.files("./functions", full.names = TRUE)

for (file in function_files) {
    source(file)
}


```

# Project Information

lorem ipsum

<details>

<summary>***About the Scenario***</summary>

## Introduction

Welcome to the Bellabeat data analysis case study! In this case study, you will perform many real-world tasks of a junior data analyst. You will imagine you are working for Bellabeat, a high-tech manufacturer of health-focused products for women, and meet different characters and team members. In order to answer the key business questions, you will follow the steps of the data analysis process: ask, prepare, process, analyze, share, and act. Along the way, the Case Study Roadmap tables — including guiding questions and key tasks — will help you stay on the right path. 

By the end of this lesson, you will have a portfolio-ready case study. Download the packet and reference the details of this case study anytime. Then, when you begin your job hunt, your case study will be a tangible way to demonstrate your knowledge and skills to potential employers.

## Scenario

You are a junior data analyst working on the marketing analyst team at Bellabeat, a high-tech manufacturer of health-focused products for women. Bellabeat is a successful small company, but they have the potential to become a larger player in the global smart device market. Urška Sršen, cofounder and Chief Creative Offcer of Bellabeat, believes that analyzing smart device fitness data could help unlock new growth opportunities for the company. You have been asked to focus on one of Bellabeat’s products and analyze smart device data to gain insight into how consumers are using their smart devices. The insights you discover will then help guide marketing strategy for the company. You will present your analysis to the Bellabeat executive team along with your high-level recommendations for Bellabeat’s marketing strategy.

## Characters and products

**_Characters_**

*Urška Sršen:* Bellabeat’s cofounder and Chief Creative Officer

*Sando Mur:* Mathematician and Bellabeat’s cofounder; key member of the Bellabeat executive team

*Bellabeat marketing analytics team:* A team of data analysts responsible for collecting, analyzing, and reporting data that helps guide Bellabeat’s marketing strategy. You joined this team six months ago and have been busy learning about Bellabeat’’s mission and business goals — as well as how you, as a junior data analyst, can help Bellabeat achieve them.

**_Products_**

*Bellabeat app:* The Bellabeat app provides users with health data related to their activity, sleep, stress, menstrual cycle, and mindfulness habits. This data can help users better understand their current habits and make healthy decisions. The Bellabeat app connects to their line of smart wellness products.

*Leaf:* Bellabeat’s classic wellness tracker can be worn as a bracelet, necklace, or clip. The Leaf tracker connects to the Bellabeat app to track activity, sleep, and stress.

*Time:* This wellness watch combines the timeless look of a classic timepiece with smart technology to track user activity, sleep, and stress. The Time watch connects to the Bellabeat app to provide you with insights into your daily wellness.

*Spring:* This is a water bottle that tracks daily water intake using smart technology to ensure that you are appropriately hydrated throughout the day. The Spring bottle connects to the Bellabeat app to track your hydration levels.

*Bellabeat membership:* Bellabeat also offers a subscription-based membership program for users. Membership gives users 24/7 access to fully personalized guidance on nutrition, activity, sleep, health and beauty, and mindfulness based on their lifestyle and goals.

## About The Company
Urška Sršen and Sando Mur founded Bellabeat, a high-tech company that manufactures health-focused smart products. Sršen used her background as an anaist to develop beautifully designed technology that informs and inspires women around the world. Collecting data on activity, sleep, stress, and reproductive health has allowed Bellabeat to empower women with knowledge about their own health and habits. Since it was founded in 2013, Bellabeat has grown rapidly and quickly positioned itself as a tech-driven wellness company for women. 

By 2016, Bellabeat had opened offices around the world and launched multiple products. Bellabeat products became available through a growing number of online retailers in addition to their own e-commerce channel on their website. The company has invested in traditional advertising media, such as radio, out-of-home billboards, print, and television, but focuses on digital marketing extensively. Bellabeat invests year-round in Google Search, maintaining active Facebook and Instagram pages, and consistently engages consumers on Twitter. Additionally, Bellabeat runs video ads on Youtube and display ads on the Google Display Network to support campaigns around key marketing dates.

Sršen knows that an analysis of Bellabeat’s available consumer data would reveal more opportunities for growth. She has asked the marketing analytics team to focus on a Bellabeat product and analyze smart device usage data in order to gain insight into how people are already using their smart devices. Then, using this information, she would like high-level recommendations for how these trends can inform Bellabeat marketing strategy.

</details>


## Ask

Sršen asks you to analyze smart device usage data in order to gain insight into how consumers use non-Bellabeat smart devices. She then wants you to select one Bellabeat product to apply these insights to in your presentation. These questions will guide your analysis:

1. What are some trends in smart device usage?
2. How could these trends apply to Bellabeat customers?
3. How could these trends help influence Bellabeat marketing strategy?

You will produce a report with the following deliverables:

1. A clear summary of the business task
2. A description of all data sources used
3. Documentation of any cleaning or manipulation of data
4. A summary of your analysis
5. Supporting visualizations and key findings
6. Your top high-level content recommendations based on your analysis

Guiding questions

* What is the problem you are trying to solve?
* How can your insights drive business decisions?

Key tasks

1. Identify the business task
2. Consider key stakeholders

Deliverable

A clear statement of the business task

## Prepare 

The data for this task was available at https://www.kaggle.com/datasets/arashnic/fitbit. It consisted of a zip file containing two files:

Fitabase Data 3.12.16-4.11.16  
Fitabase Data 4.12.16-5.12.16

For this exercise I will use only Fitabase Data 4.12.16-5.12.16 data set.

There are following 18 files in the zip file:

dailyActivity_merged.csv   
dailyCalories_merged.csv   
dailyIntensities_merged.csv  
dailySteps_merged.csv  
heartrate_seconds_merged.csv   
hourlyCalories_merged.csv  
hourlyIntensities_merged.csv   
hourlySteps_merged.csv   
minuteCaloriesNarrow_merged.csv   
minuteCaloriesWide_merged.csv  
minuteIntensitiesNarrow_merged.csv   
minuteIntensitiesWide_merged.csv   
minuteMETsNarrow_merged.csv  
minuteSleep_merged.csv   
minuteStepsNarrow_merged.csv   
minuteStepsWide_merged.csv   
sleepDay_merged.csv  
weightLogInfo_merged.csv   


I have already unzipped the data from the zip file put the csv files in my ./data folder. Now I will load each of these csv files as data frames to my global environment using this function i wrote.
```{r, load}
dataframes <- load_csv_files("./data")
```
We loaded 18 data frames. Let's have a look at the data:
```{r}
for (df_name in dataframes) {
  cat("Dataframe:", df_name, "\n")
  str(get(df_name), give.attr = FALSE)
  cat("\n")
}

```


* How is the data organized? Is it in long or wide format?

the data consist of 18 csv files, can be grouped as daily, hourly, and minutely, also has sleep, heart rate and weight log data.

dailyActivity_merged is a merge of dailyCalories_merged, dailyIntensities_merged, and dailySteps_merged. 

hourly and minutely data can also be merged by joining and assigning to dataframes hourlyActivity_merged and minuteActivity_merged respectively. 

sleepDay_merged may be considered joining with dailyActivity_merged as both are dailies.

* Are there issues with bias or credibility in this data? Does your data ROCCC?



- How are you addressing licensing, privacy, security, and accessibility?


- How did you verify the data’s integrity?


- How does it help you answer your question?


- Are there any problems with the data?

Key tasks

1. Download data and store it appropriately.
2. Identify how it’s organized.
3. Sort and alter the data.
4. Determine the credibility of the data.

Deliverable
A description of all data sources used

## Process

First of all, dailyActivity_merged dataframe is the merge of dailyCalories_merged, dailyIntensities_merged, and dailySteps_merged dataframes. I wont need those seperate dataframes, therefore I will drop those three:
```{r, daily, cache=TRUE}

rm(dailyCalories_merged, dailyIntensities_merged, dailySteps_merged)
names_to_remove <- c("dailyCalories_merged", "dailyIntensities_merged", "dailySteps_merged")
dataframes <- setdiff(dataframes, names_to_remove)
```


```{r, wides, cache=TRUE}
names_to_remove <- dataframes[grep("Wide", dataframes)]
names_to_remove <- c(names_to_remove, "minuteSleep_merged")
dataframes <- setdiff(dataframes, names_to_remove)
rm(list = grep("Wide", ls(), value = TRUE), envir = .GlobalEnv)
```

I will check for NA values in my dataframes:

```{r, na check, cache=TRUE}
for (df_name in dataframes) {
  cat( df_name, "dataframe", "has", sapply(df_name, function(x) sum(is.na(x))), "NAs.", "\n")
}

```

There are no NA's in our dataframes. 

Now I want to check for duplicates: 

```{r, detect duplicates}
for (df_name in dataframes) {
  df <- get(df_name)  
  num_duplicates <- sum(duplicated(df)) 
  cat(df_name, "has", num_duplicates, "duplicates.", "\n") 
}

```

minuteSleep_merged has 543, and sleepDay_merged has 3 duplicates. I want to remove them and recheck.

```{r, remove duplicates, cache=TRUE}
dataframes_with_duplicates <- c("minuteSleep_merged", "sleepDay_merged")
minuteSleep_merged <- minuteSleep_merged[!duplicated(minuteSleep_merged), ]
sleepDay_merged <- sleepDay_merged[!duplicated(sleepDay_merged), ]


for (df_name in dataframes_with_duplicates) {
  df <- get(df_name)  
  num_duplicates <- sum(duplicated(df)) 
  cat(df_name, "has", num_duplicates, "duplicates.", "\n") 
}

```
For each data frame we have varying shapes of observations and variables, which range from 940 to ~2.5M. First thing we see is that the variables related to dates and times have <chr> datatypes.  This indicates the data is stored as text data, and will create problems in comparisons and calculations. I want to convert them to proper date and time datatypes, i.e. POSIXcts.
dailyActivity_merged data frame has a date variable containing only date strings in %m/%d/%Y format and can easily be converted to POSIXct:
``` {r, dates}
dailyActivity_merged$Date <- as.POSIXct(dailyActivity_merged$ActivityDate, 
                                                format = "%m/%d/%Y", 
                                                tz = "UTC")

dailyActivity_merged <- subset(dailyActivity_merged, select = -ActivityDate)

```

Also the datetime values need to be splitted and properly formatted in the other data frames too. That could be time consuming for all those 14 data frames, therefore I wrote a split_datetime_column function to find and format those values. I will use the function iteratively on the data frames that are not dailyActivity_merged, splitting dates and times, and then splits the time values Hour, Minute, and Second variables. 


```{r, datetimes}

filtered_dataframes <- dataframes[!grepl("daily", dataframes)]
for (df_name in filtered_dataframes) {
  cat(df_name, "... ")
  split_datetime_column(df_name)
  cat("done.", "\n")
}

```
heartrate_seconds_merged dataframe has a seconds variable, but I have nothing in other data frames that can be compared with that. I will get the mean heart rates for each minute using the values of seconds. 

```{r, heartrate_seconds_merged, cache=TRUE}
heartrate_seconds_merged <- heartrate_seconds_merged %>% group_by(Id, Date, Hour, Minute) %>% summarise(mean_HR = mean(Value))
```
In weightLogInfo_merged we only have LogId variable to differentiate the information and we do not have to relate it with time or anything else, therefore I will group the data by Ids and have a mean weight for each person.

``` {r, weight}
weightLogInfo_merged <- weightLogInfo_merged %>%
  select(Id, WeightKg, BMI) %>% group_by(Id) %>% summarise(mean_weight = mean(WeightKg), mean_BMI = mean(BMI))
```


Let's have a quick look to updated dataframes:

```{r}
for (df_name in dataframes) {
  cat("Dataframe:", df_name, "\n")
  print(head(get(df_name),5))
  cat("\n")
}
```

I am planning to merge hourly and minutely data frames to work more efficiently, but before that I want to check if each data frame share an Id variable.

```{r, merge check, cache=TRUE}
for (df_name in dataframes) {
  df <- get(df_name) 
  if ("Id" %in% colnames(df)) {
    cat(df_name, "Id variable found.\n")
  } else {
    cat(df_name, "has no Id variable.\n")
  }
}

```
Now I will create a hourly_merged dataframe by joining all the hourly* dataframes.

``` {r, hourly}
names_to_remove <- dataframes[grep("hourly", dataframes)]
lapply(names_to_remove, drop_second_column)
dataframes <- setdiff(dataframes, names_to_remove)
hourly_merged <- full_join(hourlyCalories_merged, hourlyIntensities_merged)
hourly_merged <- full_join(hourly_merged, hourlySteps_merged)
dataframes <- c(dataframes, "hourly_merged")
rm(list = grep("^hourly(?!_)", ls(), perl = TRUE, value = TRUE), envir = .GlobalEnv)
```

I will do the same for minute* dataframes.

``` {r, minutely}
names_to_remove <- dataframes[grep("minute", dataframes)]
lapply(names_to_remove, drop_second_column)
dataframes <- setdiff(dataframes, names_to_remove)
minutely_merged <- inner_join(minuteCaloriesNarrow_merged, minuteIntensitiesNarrow_merged)
minutely_merged <- inner_join(minutely_merged, minuteMETsNarrow_merged)
minutely_merged <- inner_join(minutely_merged, minuteStepsNarrow_merged)

dataframes <- c(dataframes, "minutely_merged")
rm(list = ls()[grepl("^minute(?!ly)", ls(), perl = TRUE)], envir = .GlobalEnv)

```
```{r, nas after joins}
sapply(hourly_merged, function(x) sum(is.na(x)))
sapply(minutely_merged, function(x) sum(is.na(x)))
```

Then, process your data for analysis using the following Case Study Roadmap as a guide:

Case Study Roadmap - Process 

Guiding questions

- What tools are you choosing and why?
- Have you ensured your data’s integrity?
- What steps have you taken to ensure that your data is clean?
- How can you verify that your data is clean and ready to analyze?
- Have you documented your cleaning process so you can review and share those results?

Key tasks

1. Check the data for errors.
2. Choose your tools.
3. Transform the data so you can work with it effectively.
4. Document the cleaning process.

Deliverable

Documentation of any cleaning or manipulation of data

## Analyze
Now that your data is stored appropriately and has been prepared for analysis, start putting it to work. Use the following Case Study Roadmap as a guide:

Case Study Roadmap - Analyze

Guiding questions

- How should you organize your data to perform analysis on it?
- Has your data been properly formatted?
- What surprises did you discover in the data?
- What trends or relationships did you and in the data?
- How will these insights help answer your business questions?

Key tasks

1. Aggregate your data so it’s useful and accessible.
2. Organize and format your data.
3. Perform calculations.
4. Identify trends and relationships.

Deliverable

A summary of your analysis

To get started in R
Open your preferred version of R, click this link, and select “Use template.” Then, copy and paste the text from the template into an R script.

1. Begin importing your data.
2. Explore your data, gathering some summary statistics
3. Clean and transform your data to prepare for analysis
4. Create some initial exploratory visualizations

## Share

Once you have completed your analysis, create your data visualizations. The visualizations should clearly communicate your high-level insights and recommendations. Use the following Case Study Roadmap as a guide:

Case Study Roadmap - Share

Guiding questions

- Were you able to answer the business questions?
- What story does your data tell?
- How do your findings relate to your original question?
- Who is your audience? What is the best way to communicate with them?
- Can data visualization help you share your findings?
- Is your presentation accessible to your audience?

Key tasks

1. Determine the best way to share your findings.
2. Create effective data visualizations.
3. Present your findings.
4. Ensure your work is accessible.

Deliverable
Supporting visualizations and key findings

Follow these steps:

1. Take out a piece of paper and a pen and sketch some ideas for how you will visualize the data. 
2. Once you choose a visual form, open your tool of choice to create your visualization. Use a presentation software, such as PowerPoint or Google Slides; your spreadsheet program; Tableau; or R.
3. Create your data visualization, remembering that contrast should be used to draw your audience’s attention to the most important insights. Use artistic principles including size, color, and shape.
4. Ensure clear meaning through the proper use of common elements, such as headlines, subtitles, and labels. 
5. Refine your data visualization by applying deep attention to detail.

## Act

Now that you have finished creating your visualizations, act on your findings. Prepare the deliverables you have been asked to create, including the high-level recommendations based on your analysis. Use the following Case Study Roadmap as a guide:

Case Study Roadmap - Act

Guiding questions

- What is your final conclusion based on your analysis?
- How could your team and business apply your insights?
- What next steps would you or your stakeholders take based on your findings?
- Is there additional data you could use to expand on your findings?

Key tasks
- Create your portfolio.
- Add your case study.
- Practice presenting your case study to a friend or family member.

Deliverable

Your top high-level insights based on your analysis

Follow these steps:

1. If you do not have one already, create an online portfolio. (Use Build a Portfolio with Google Sites.)
2. Consider how you want to feature your case study in your porftolio.
3. Upload or link your case study findings to your portfolio.
4. Write a brief paragraph describing the case study, your process, and your discoveries.
5. Add the paragraph to introduce your case study in your portfolio.